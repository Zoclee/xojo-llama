# xojo-llama
A wrapper module to do LLM inference on GGUF models using the llama.cpp binaries. 

## Support the Project

[![Donate](https://img.shields.io/badge/Donate-PayPal-blue.svg)](https://www.paypal.com/donate/?business=accounts@zoclee.com&no_recurring=0&currency_code=USD)
